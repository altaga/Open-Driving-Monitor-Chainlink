{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/altaga/Open-Driving-Monitor/blob/main/Drowsiness/train/Train_Test_and_Deploy_Blink.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing modules"
      ],
      "metadata": {
        "id": "EtXBDa_6Y648"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbvI8wJd_-99"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Conv2D, Flatten, Dense, AveragePooling2D, Dropout, MaxPooling2D,Activation,BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset and Haarcascades"
      ],
      "metadata": {
        "id": "oI60zbuAY__A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/altaga/DBSE-monitor/raw/master/Drowsiness/train/dataset/dataset_B_Eye_Images.zip -O temp.zip\n",
        "!unzip temp.zip\n",
        "!rm temp.zip\n",
        "!wget https://github.com/altaga/DBSE-monitor/blob/master/Drowsiness/train/haar_models/haarcascade_eye.xml\n",
        "!wget https://github.com/altaga/DBSE-monitor/blob/master/Drowsiness/train/haar_models/haarcascade_frontalface_default.xml"
      ],
      "metadata": {
        "id": "SYk3nEKtAapI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up training"
      ],
      "metadata": {
        "id": "gSmYJQWGZEbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 2\n",
        "IMG_SIZE = 24\n",
        "# Training Parameters\n",
        "n_epochs = 20\n",
        "batch_size = 64\n",
        "weight_decay = 1e-4"
      ],
      "metadata": {
        "id": "hZkIaBNkAEdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup support functions for processing and training."
      ],
      "metadata": {
        "id": "BI017wZ1ZMwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap_frozen_graph(graph_def, inputs, outputs, print_graph=False):\n",
        "    def _imports_graph_def():\n",
        "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
        "\n",
        "    wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\n",
        "    import_graph = wrapped_import.graph\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Frozen model layers: \")\n",
        "    layers = [op.name for op in import_graph.get_operations()]\n",
        "    if print_graph == True:\n",
        "        for layer in layers:\n",
        "            print(layer)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return wrapped_import.prune(\n",
        "        tf.nest.map_structure(import_graph.as_graph_element, inputs),\n",
        "        tf.nest.map_structure(import_graph.as_graph_element, outputs))"
      ],
      "metadata": {
        "id": "tGWyDJDlAMeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the model and training with the entire data set."
      ],
      "metadata": {
        "id": "c-x9LuJEZaLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "files = list(map(lambda x: {'file': x, 'label':1}, glob.glob('dataset_B_Eye_Images/openRightEyes/*.jpg')))\n",
        "files.extend(list(map(lambda x: {'file': x, 'label':1}, glob.glob('dataset_B_Eye_Images/openLeftEyes/*.jpg'))))\n",
        "files.extend(list(map(lambda x: {'file': x, 'label':0}, glob.glob('dataset_B_Eye_Images/closedLeftEyes/*.jpg'))))\n",
        "files.extend(list(map(lambda x: {'file': x, 'label':0}, glob.glob('dataset_B_Eye_Images/closedRightEyes/*.jpg'))))\n",
        "\n",
        "for file in files:\n",
        "    img = cv2.imread(file['file'])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    images.append(np.array(img))\n",
        "    labels.append(file['label'])\n",
        "\n",
        "labels = np_utils.to_categorical(labels, NUM_CLASSES)\n",
        "images = np.array(images)\n",
        "images = images.astype('float32') / 255.0\n",
        "\n",
        "print(labels.shape)\n",
        "print(images.shape)\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,labels,\n",
        "                                  random_state=104,\n",
        "                                  test_size=0.4,\n",
        "                                  shuffle=True)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test ,\n",
        "                              random_state=104,\n",
        "                              test_size=0.3,\n",
        "                              shuffle=True)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "# 1st convolution layer\n",
        "model.add(Conv2D(64, (8,8), activation='relu', input_shape=(24, 24, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "# 1st Dropout\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.1))\n",
        "# 2nd convolution layer\n",
        "model.add(Conv2D(128, (8,8), padding='same', kernel_regularizer= l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "# 2nd Dropout\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.2))\n",
        "# Flatten\n",
        "model.add(Flatten())\n",
        "# 1st Dense\n",
        "model.add(Dense(512, activation=\"linear\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation=\"linear\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Output Layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    epochs=n_epochs, batch_size=batch_size)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "\n",
        "print(\"Training Score: {}\".format(score))\n",
        "model.fit(X_test, y_test,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    epochs=int(n_epochs/2), batch_size=batch_size)\n",
        "model.fit(X_valid, y_valid, epochs=int(n_epochs/2), batch_size=batch_size)\n",
        "\n",
        "print(\"Model trained with all data\")"
      ],
      "metadata": {
        "id": "HYevbVJXANED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download test image"
      ],
      "metadata": {
        "id": "UzIy7PrRbAHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/altaga/Open-Driving-Monitor/main/Drowsiness/test/testImages/open1.png"
      ],
      "metadata": {
        "id": "KYErGXJOa_tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model"
      ],
      "metadata": {
        "id": "c0YE11qTZjuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image from disk\n",
        "class_names = [\n",
        "    'Close',\n",
        "    'Open',\n",
        "]\n",
        "\n",
        "image = cv2.imread('open.png')\n",
        "imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "imageGray3 = cv2.cvtColor(imageGray, cv2.COLOR_GRAY2BGR)\n",
        "imageGray3res = cv2.resize(imageGray3, (24, 24),  interpolation=cv2.INTER_AREA)\n",
        "imageNP = np.array(imageGray3res)\n",
        "imageNormal = imageNP.astype('float32') / 255.0\n",
        "plt.imshow(imageRGB)\n",
        "data = np.expand_dims(imageNormal, 0)\n",
        "outputs = model.predict(data)\n",
        "# Get Values\n",
        "final_outputs = outputs[0]\n",
        "# get the class label\n",
        "label_id = np.argmax(final_outputs)\n",
        "out_name = class_names[label_id]\n",
        "print(out_name)"
      ],
      "metadata": {
        "id": "8dLA6LY4m05e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a forzen graph that can be used in OpenCV DNN"
      ],
      "metadata": {
        "id": "fvGMY4bbZtTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Keras model to ConcreteFunction\n",
        "full_model = tf.function(lambda x: model(x))\n",
        "full_model = full_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name=\"emotion\"))\n",
        "# Get frozen ConcreteFunction\n",
        "frozen_func = convert_variables_to_constants_v2(full_model)\n",
        "frozen_func.graph.as_graph_def()\n",
        "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
        "print(\"-\" * 50)\n",
        "print(\"Frozen model layers: \")\n",
        "for layer in layers:\n",
        "    print(layer)\n",
        "print(\"-\" * 50)\n",
        "print(\"Frozen model inputs: \")\n",
        "print(frozen_func.inputs)\n",
        "print(\"Frozen model outputs: \")\n",
        "print(frozen_func.outputs)\n",
        "# Save frozen graph from frozen ConcreteFunction to hard drive\n",
        "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
        "                  logdir=\"./frozen_models\",\n",
        "                  name=\"frozen_graph.pb\",\n",
        "                  as_text=False)"
      ],
      "metadata": {
        "id": "R4fiEuehe1Rw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}