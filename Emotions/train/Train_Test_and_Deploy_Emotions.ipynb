{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/altaga/Open-Driving-Monitor/blob/main/Emotions/train/Train_Test_and_Deploy_Emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing modules"
      ],
      "metadata": {
        "id": "EtXBDa_6Y648"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbvI8wJd_-99"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import Conv2D, Flatten, Dense, AveragePooling2D, Dropout, MaxPooling2D,Activation,BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the Dataset"
      ],
      "metadata": {
        "id": "oI60zbuAY__A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/spaces/mxz/emtion/resolve/c697775e0adc35a9cec32bd4d3484b5f5a263748/fer2013.csv"
      ],
      "metadata": {
        "id": "SYk3nEKtAapI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up training"
      ],
      "metadata": {
        "id": "gSmYJQWGZEbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 7\n",
        "IMG_SIZE = 48\n",
        "# Training Parameters\n",
        "n_epochs = 30\n",
        "batch_size = 128\n",
        "weight_decay = 1e-4"
      ],
      "metadata": {
        "id": "hZkIaBNkAEdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup support functions for processing and training."
      ],
      "metadata": {
        "id": "BI017wZ1ZMwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pandas_vector_to_list(pandas_df):\n",
        "    py_list = [item[0] for item in pandas_df.values.tolist()]\n",
        "    return py_list\n",
        "\n",
        "def process_emotion(emotion):\n",
        "    emotion_as_list = pandas_vector_to_list(emotion)\n",
        "    y_data = []\n",
        "    for index in range(len(emotion_as_list)):\n",
        "        y_data.append(emotion_as_list[index])\n",
        "\n",
        "    # Y data\n",
        "    y_data_categorical = np_utils.to_categorical(y_data, NUM_CLASSES)\n",
        "    return y_data_categorical\n",
        "\n",
        "\n",
        "def process_pixels(pixels, img_size=IMG_SIZE):\n",
        "    pixels_as_list = pandas_vector_to_list(pixels)\n",
        "    np_image_array = []\n",
        "    for index, item in enumerate(pixels_as_list):\n",
        "        # 48x48\n",
        "        data = np.zeros((img_size, img_size), dtype=np.uint8)\n",
        "        # split space separated ints\n",
        "        pixel_data = item.split()\n",
        "\n",
        "        # 0 -> 47, loop through the rows\n",
        "        for i in range(0, img_size):\n",
        "            # (0 = 0), (1 = 47), (2 = 94), ...\n",
        "            pixel_index = i * img_size\n",
        "            # (0 = [0:47]), (1 = [47: 94]), (2 = [94, 141]), ...\n",
        "            data[i] = pixel_data[pixel_index:pixel_index + img_size]\n",
        "\n",
        "        np_image_array.append(np.array(data))\n",
        "\n",
        "    np_image_array = np.array(np_image_array)\n",
        "    # convert to float and divide by 255\n",
        "    np_image_array = np_image_array.astype('float32') / 255.0\n",
        "    return np_image_array\n",
        "\n",
        "\n",
        "def duplicate_input_layer(array_input, size):\n",
        "    vg_input = np.empty([size, 48, 48, 3])\n",
        "    for index, item in enumerate(vg_input):\n",
        "        item[:, :, 0] = array_input[index]\n",
        "        item[:, :, 1] = array_input[index]\n",
        "        item[:, :, 2] = array_input[index]\n",
        "    return vg_input\n",
        "\n",
        "def wrap_frozen_graph(graph_def, inputs, outputs, print_graph=False):\n",
        "    def _imports_graph_def():\n",
        "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
        "\n",
        "    wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\n",
        "    import_graph = wrapped_import.graph\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Frozen model layers: \")\n",
        "    layers = [op.name for op in import_graph.get_operations()]\n",
        "    if print_graph == True:\n",
        "        for layer in layers:\n",
        "            print(layer)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return wrapped_import.prune(\n",
        "        tf.nest.map_structure(import_graph.as_graph_element, inputs),\n",
        "        tf.nest.map_structure(import_graph.as_graph_element, outputs))"
      ],
      "metadata": {
        "id": "tGWyDJDlAMeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the model and training with the entire data set."
      ],
      "metadata": {
        "id": "c-x9LuJEZaLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data in a Pandas dataframe\n",
        "raw_data = pd.read_csv(\"fer2013.csv\")\n",
        "\n",
        "# convert to one hot vectors\n",
        "emotion_array = process_emotion(raw_data[['emotion']])\n",
        "\n",
        "# convert to a 48x48 float matrix\n",
        "pixel_array = process_pixels(raw_data[['pixels']])\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(pixel_array,emotion_array ,\n",
        "                                  random_state=104,\n",
        "                                  test_size=0.4,\n",
        "                                  shuffle=True)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test ,\n",
        "                              random_state=104,\n",
        "                              test_size=0.3,\n",
        "                              shuffle=True)\n",
        "\n",
        "n_train = int(len(X_train))\n",
        "n_test = int(len(X_test))\n",
        "n_valid = int(len(X_valid))\n",
        "\n",
        "x_train_input = duplicate_input_layer(X_train, n_train)\n",
        "x_test_input = duplicate_input_layer(X_test, n_test)\n",
        "x_valid_input = duplicate_input_layer(X_valid, n_valid)\n",
        "print(x_train_input.dtype)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "# 1st convolution layer\n",
        "model.add(Conv2D(64, (8,8), activation='relu', input_shape=(48, 48, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "# 1st Dropout\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.1))\n",
        "# 2nd convolution layer\n",
        "model.add(Conv2D(128, (8,8), padding='same', kernel_regularizer= l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "# 2nd Dropout\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.2))\n",
        "# 3rd convolution layer\n",
        "model.add(Conv2D(256, (8,8), padding='same', kernel_regularizer= l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "# 3rd Dropout\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.4))\n",
        "# Flatten\n",
        "model.add(Flatten())\n",
        "# 1st Dense\n",
        "model.add(Dense(512, activation=\"linear\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation=\"linear\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Output Layer\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train_input, y_train,\n",
        "                    validation_data=(x_valid_input, y_valid),\n",
        "                    epochs=n_epochs, batch_size=batch_size)\n",
        "\n",
        "score = model.evaluate(x_test_input, y_test, batch_size=batch_size)\n",
        "\n",
        "print(\"Training Score: {}\".format(score))\n",
        "model.fit(x_test_input, y_test,\n",
        "                    validation_data=(x_valid_input, y_valid),\n",
        "                    epochs=int(n_epochs/2), batch_size=batch_size)\n",
        "model.fit(x_valid_input, y_valid, epochs=int(n_epochs/2), batch_size=batch_size)\n",
        "\n",
        "print(\"Model trained with all data\")"
      ],
      "metadata": {
        "id": "HYevbVJXANED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download test image"
      ],
      "metadata": {
        "id": "UzIy7PrRbAHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/altaga/Open-Driving-Monitor/main/Emotions/test/testImages/Happy1.png"
      ],
      "metadata": {
        "id": "KYErGXJOa_tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model"
      ],
      "metadata": {
        "id": "c0YE11qTZjuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image from disk\n",
        "class_names = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
        "\n",
        "image = cv2.imread('Happy1.png')\n",
        "color = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "resized = cv2.resize(color, (48, 48),  interpolation=cv2.INTER_AREA)\n",
        "plt.imshow(color)\n",
        "data = np.expand_dims(resized, 0)\n",
        "outputs = model.predict(data)\n",
        "# Get Values\n",
        "final_outputs = outputs[0]\n",
        "# get the class label\n",
        "label_id = np.argmax(final_outputs)\n",
        "out_name = class_names[label_id]\n",
        "print(out_name)"
      ],
      "metadata": {
        "id": "8dLA6LY4m05e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a forzen graph that can be used in OpenCV DNN"
      ],
      "metadata": {
        "id": "fvGMY4bbZtTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Keras model to ConcreteFunction\n",
        "full_model = tf.function(lambda x: model(x))\n",
        "full_model = full_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name=\"emotion\"))\n",
        "# Get frozen ConcreteFunction\n",
        "frozen_func = convert_variables_to_constants_v2(full_model)\n",
        "frozen_func.graph.as_graph_def()\n",
        "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
        "print(\"-\" * 50)\n",
        "print(\"Frozen model layers: \")\n",
        "for layer in layers:\n",
        "    print(layer)\n",
        "print(\"-\" * 50)\n",
        "print(\"Frozen model inputs: \")\n",
        "print(frozen_func.inputs)\n",
        "print(\"Frozen model outputs: \")\n",
        "print(frozen_func.outputs)\n",
        "# Save frozen graph from frozen ConcreteFunction to hard drive\n",
        "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
        "                  logdir=\"./frozen_models\",\n",
        "                  name=\"frozen_graph.pb\",\n",
        "                  as_text=False)"
      ],
      "metadata": {
        "id": "R4fiEuehe1Rw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}